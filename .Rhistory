scale_y_reverse()
ggplot(subset(observed_df, year == 2010), aes(DateTime, as.numeric(Depth))) +
geom_raster(aes(fill = as.numeric(var)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(-2,30),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth') +
labs(fill = 'Temp. [degC]') +
scale_y_reverse()
ggsave('cont.png', units = 'in', dpi=300, width = 15, height = 10)
getwd()
ggsave('cont.png', units = 'in', dpi=300, width = 30, height = 20)
library(tidyverse)
library(rLakeAnalyzer)
library(lubridate)
install.packages("tidyverse")
library(tidyverse)
library(tidyverse)
library(tidyverse)
######################################
## R is a calculator
5 +4
8/2
# 5 + 4
(2 + 7) *3
######################################
## WHAT IS AN OBJECT?
## Saving objects in R, and viewing object data
## (Environment Pane; how to name "best" - must begin with letter, caps or lowercase accepted;
## name objects clearly and consistently)
a <- 5+4
a
b <- 8/2
b
c = 19+5
c
######################################
## Errors and warning messages
## Errors BREAK the code, warnings run it (often not an issue, but keep an eye out that R is doing what you want)
## A
## c <- b - 3) * 2
## cbind(c(1, 2, 3), c(1, 2, 3, 4))
a
A
b -3)*2
cbind(c(1,2,3),c(1,2,3,4))
## Basic functions and help files
?mean
?c
# ?mean
# ?c
vector1 <- c(1,2,3,4,5)
vector1
# vector1 <- c(1, 2, 3, 4, 5)
# vector1
#
mean(vector1)
sqrt(vector1)
?sqrt
vector1 + vector1
df1 <- data.frame('Column1' = c('A','B','C','D','E'),
'Col2' = vector1,
'ColumThree' = c('I', 'am', 'doing', 'data', 'stuff'))
df1
str(df1)
?str
'ColumThree' = c('I', 'am', 'doing', 'data', "stuff'))
df1 <- data.frame('Column1' = c('A','B','C','D','E'),
'Col2' = vector1,
'ColumThree' = c('I', 'am', 'doing', 'data', "stuff"))
df1$ColumThree
# df1 <- data.frame("Column1" = c("A", "B", "C", "D", "E"),
#                   "Column2" = vector1,
#                   "Column3" = c("I", "am", "doing", "data", "science"))
# df1
#
head(df1)
# df1 <- data.frame("Column1" = c("A", "B", "C", "D", "E"),
#                   "Column2" = vector1,
#                   "Column3" = c("I", "am", "doing", "data", "science"))
# df1
#
head(df1, n = 3)
tail(df1, n = 1)
str(dt1)
str(df1)
summary(df1)
## 1) load in the data file and peek at the columns/structure
file <- file.choose()
file
birds <- read.csv(file)
## 1) load in the data file and peek at the columns/structure
file <- file.choose()
birds
head(birds)
str(birds)
## 2) calculate the average, maximum and minimum annual count column
mean(birds$AnnualCount)
max(birds$AnnualCount)
min(birds$AnnualCount)
## 3) find the earliest and latest year of data
min(birds$Year)
max(birds$Year)
## OR
range(birds$Year)
birds$CommonName[which.max(birds$AnnualCount)]
birds$Year[which.max(birds$AnnualCount)]
# birds$CommonName[which.max(birds$AnnualCount)]
# birds$Year[which.max(birds$AnnualCount)]
#
unique(birds$CommonName)
length(unique(birds$CommonName))
mean(birds$AnnualCount[birds$Year == 2010 & birds$MigrationType == 'Long distance migrant'])
#### choose specific column(s) by name
BirdNamesCounts <- select(birds, CommonName, AnnualCount)
BirdNamesCounts
str(BirdNamesCounts)
#### choose row(s) by condition
Year2016 <- filter(birds, Year == 2016)
Year2016
## create new column(s)
AboveBelow <- mutate(birds, AboveBelowAvg = ifelse(AnnualCount > 8, TRUE, FALSE))
AboveBelow
## summarize (must become fewer rows than original)
# MeanCount <- summarize(birds, MeanCount = mean(AnnualCount))
# MeanCount
MeanCount(summarize(birds,MeanCount == mean(AnnualCount)))
## summarize (must become fewer rows than original)
# MeanCount <- summarize(birds, MeanCount = mean(AnnualCount))
# MeanCount
MeanCount<- summarize(birds,MeanCount == mean(AnnualCount))
## summarize (must become fewer rows than original)
# MeanCount <- summarize(birds, MeanCount = mean(AnnualCount))
# MeanCount
MeanCount<- summarize(birds,MeanCount = mean(AnnualCount))
MeanCount
# AboveBelow <- mutate(birds, AboveBelowAvg = ifelse(AnnualCount > 8, TRUE, FALSE))
# AboveBelow
str(AboveBelow)
AboveBelow$AboveBelowAvg
PopularBirds <- birds %>%
filter(AnnualCount >= 8) %>%
select(Year, CommonName, AnnualCount)
PopularBirds
unique(PopularBirds$CommonName)
TotalByMigration <- birds %>%
group_by(Year, MigrationType) %>%
summarize(TotalCount = sum(AnnualCount))
TotalByMigration
RecentCardinals <- birds %>%
filter(Year >= 2010,
CommonName == "Northern Cardinal") %>%
summarize(AvgCardinals = mean(AnnualCount))
RecentCardinals
TotalByMigration
birdsWide <- TotalByMigration %>%
select(Year, MigrationType, TotalCount) %>%
spread(key = MigrationType, value = TotalCount) %>%
rename(LongDistance = 'Long distance migrant',
ShortDistance = 'Short distance migrant')
birdsWide
TotalByMigration
birdsWide
TotalByMigration
boxplot(TotalCount ~ MigrationType,data = TotalByMigration)
TotalByMigration
#
boxplot(TotalCount ~ MigrationType,data = TotalByMigration,
xlab = "Migration Type",
ylab = "Annual Count")
plot(LongDistance ~ Year, data = birdsWide,
xlab = "Annual Count",
main = "Annual Counts of Long Distance Bird Migrants over Time",
pch = 19,
type = "o")
abline(lm(LongDistance ~ Year, data = birdsWide),
lty = 2)
#
boxplot(TotalCount ~ MigrationType,data = TotalByMigration,
xlab = "Migration Type",
ylab = "Annual Count")
plot(LongDistance ~ Year, data = birdsWide,
xlab = "Annual Count",
main = "Annual Counts of Long Distance Bird Migrants over Time",
pch = 19,
type = "o")
lines(LongDistance + sd(LongDistance) ~ Year, data = birdsWide)
plot(LongDistance ~ Year, data = birdsWide,
xlab = "Annual Count",
main = "Annual Counts of Long Distance Bird Migrants over Time",
pch = 19,
type = "o")
lines(LongDistance + sd(LongDistance) ~ Year, data = birdsWide)
lines(LongDistance - sd(LongDistance) ~ Year, data = birdsWide)
abline(lm(LongDistance ~ Year, data = birdsWide),
lty = 2)
?plot
ggplot(TotalByMigration, aes(Year, TotalCount, col = MigrationType)) +
geom_point() +
geom_line() +
geom_smooth(method=lm) +
theme_minimal()
cor(x = birdsWide$LongDistance, y = birdsWide$Resident)
t.test(x = birdsWide$LongDistance, y = birdsWide$Resident)
bird.anova <- aov(TotalCount ~ MigrationType, data = TotalByMigration)
summary(bird.anova)
bird.anova <- aov(TotalCount ~ MigrationType, data = TotalByMigration)
summary(bird.anova)
source("~/Projects/teaching/introdatasciencer/livecoding.R", echo=TRUE)
TukeyHSD(bird.anova)
plot(LongDistance ~ Year, data = birdsWide,
xlab = "Annual Count",
main = "Annual Counts of Long Distance Bird Migrants over Time",
pch = 19,
type = "o")
abline(lm(LongDistance ~ Year, data = birdsWide),
lty = 2)
bird.mod <- lm(LongDistance ~ Year, data = birdsWide)
summary(bird.mod)
bird.anova <- aov(TotalCount ~ MigrationType, data = TotalByMigration)
summary(bird.anova)
TukeyHSD(bird.anova)
plot(TukeyHSD(bird.anova, conf.level=.95), las = 2)
TukeyHSD(bird.anova)
require(remotes)
isntall_github('robertladwig/LakeModelR')
install_github('robertladwig/LakeModelR')
install_github('robertladwig/LakeModelR')
install_github('robertladwig/LakeModelR')
## CLEAN WORKSPACE
rm(list = ls())
## LOAD PACKAGE(S)
library(LakeModelR)
require(tidyverse)
## GENERAL LAKE CONFIGURATION
zmax = 25 # maximum lake depth
nx = 25 # number of layers we want to have
dt = 3600  # temporal step (here, one hour because it fits boundary data)
dx = zmax/nx # spatial step
## HYPSOGRAPHY OF THE LAKE
hyps_all <- get_hypsography(hypsofile = system.file('extdata', 'bathymetry.csv',
package = 'LakeModelR'),
dx = dx, nx = nx)
## LOAD PACKAGE(S)
library(LakeModelR)
require(tidyverse)
## GENERAL LAKE CONFIGURATION
zmax = 25 # maximum lake depth
nx = 25 # number of layers we want to have
dt = 3600  # temporal step (here, one hour because it fits boundary data)
dx = zmax/nx # spatial step
## HYPSOGRAPHY OF THE LAKE
hyps_all <- get_hypsography(hypsofile = system.file('extdata', 'bathymetry.csv',
package = 'LakeModelR'),
dx = dx, nx = nx)
## ATMOSPHERIC BOUNDARY CONDITIONS
meteo_all <- provide_meteorology(meteofile = system.file('extdata', 'meteorology.csv',
package = 'LakeModelR'),
secchifile = NULL)
### TIME INFORMATION
startingDate <- meteo_all[[1]]$datetime[1]
startTime = 1
endTime = 365 *24 * 3600 # seconds
total_runtime = endTime / 24 / 3600 # days
# INTERPOLATE ATMOSPHERIC BOUNDARY CONDITIONS
meteo = get_interp_drivers(meteo_all = meteo_all,
total_runtime = total_runtime,
dt = dt,
method = "integrate",
secchi = F)
## DEFINE INITIAL WATER TEMPERATURE FROM OBSERVED DATA
u_ini <- initial_profile(initfile = system.file('extdata', 'observedTemp.txt',
package = 'LakeModelR'),
nx = nx, dx = dx,
depth = hyps_all[[2]],
processed_meteo = meteo_all[[1]])
## RUN THE LAKE MODEL
res <-  run_thermalmodel(u = u_ini,
startTime = startTime,
endTime =  endTime,
ice = FALSE,
Hi = 0,
iceT = 6,
supercooled = 0,
kd_light = 0.5,
sw_factor = 1.0,
zmax = zmax,
nx = nx,
dt = dt,
dx = dx,
area = hyps_all[[1]], # area
depth = hyps_all[[2]], # depth
volume = hyps_all[[3]], # volume
daily_meteo = meteo,
Cd = 0.0013,
scheme = 'implicit')
## SAVE THE RESULTS
temp = res$temp
mixing = res$mixing
ice = res$icethickness
avgtemp = res$average
## POST-PROCESSING OF THE RESULTS
time =  startingDate + seq(1, ncol(temp), 1) * dt
avgtemp = as.data.frame(avgtemp)
colnames(avgtemp) = c('time', 'epi', 'hyp', 'tot', 'stratFlag', 'thermoclineDep')
avgtemp$time = time
## AVERAGE TEMPERATURES IN EPILIMNION AND HYPOLIMNION
ggplot(avgtemp) +
geom_line(aes(time, epi, col = 'epilimnion')) +
geom_line(aes(time, hyp, col = 'hypolimnion')) +
geom_line(aes(time, tot, col = 'total')) +
theme_minimal()
## CREATE DATAFRAME FOR FULL TEMPERATURE PROFILES
df <- data.frame(cbind(time, t(temp)) )
colnames(df) <- c("time", as.character(paste0(seq(1,nrow(temp)))))
m.df <- reshape2::melt(df, "time")
m.df$time <- time
## CREATE DATAFRAME FOR ICE
df.ice = data.frame('time' = time,
'ice_h' = ice)
## HEATMAP OF WATER TEMPERATURE WITH THERMOCLINE DEPTH AND ICE THICKNESS
ggplot(m.df, aes((time), dx*as.numeric(as.character(variable)))) +
geom_raster(aes(fill = as.numeric(value)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(-1,30),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth [m]') +
labs(fill = 'Temp [degC]')+
geom_line(data = avgtemp, aes(time, thermoclineDep, col = 'thermocline depth'), linetype = 'dashed', col = 'brown') +
geom_line(data = df.ice, aes(time, ice_h * (-1), col = 'ice thickness'), linetype = 'solid', col = 'darkblue') +
scale_y_reverse()
setwd('../lake_trophic_status/')
setwd('../lake_trophic_status/')
item = 1
n = 5
x = 0
while(item <= n){
x <- x + item
item = item + 1
}
print(x)
time = 100
space = 100
conc >- matrix(0, nrow = space, ncol = time)
time = 100
space = 100
conc <- matrix(0, nrow = space, ncol = time)
K = 0.5
dx = 1
dt = 1
conc <- dnorm(seq(1,space,1), mean = 50, sd = 1) * 100
for (n in 2:ncol(conc)){
for (i in 2:(nrow(conc)-1)){
conc[i, n] = conc[i, n-1] +  K * dt/dx**2 * (conc[i-1, n-1] - 2 * conc[i, n-1] + conc[i+1, n-1])
}
}
time = 100
space = 100
conc <- matrix(0, nrow = space, ncol = time)
K = 0.5
dx = 1
dt = 1
conc[, 1] <- dnorm(seq(1,space,1), mean = 50, sd = 1) * 100
for (n in 2:ncol(conc)){
for (i in 2:(nrow(conc)-1)){
conc[i, n] = conc[i, n-1] +  K * dt/dx**2 * (conc[i-1, n-1] - 2 * conc[i, n-1] + conc[i+1, n-1])
}
}
conc
plot(conc[,1])
dev.off()
plot(conc[,1])
conc[,1]
time = 100
space = 100
conc <- matrix(0, nrow = space, ncol = time)
K = 0.5
dx = 1
dt = 1
conc[, 1] <- dnorm(seq(1,space,1), mean = 50, sd = 1) * 100
for (n in 2:ncol(conc)){
for (i in 2:(nrow(conc)-1)){
conc[i, n] = conc[i, n-1] +  K * dt/dx^2 * (conc[i-1, n-1] - 2 * conc[i, n-1] + conc[i+1, n-1])
}
}
plot(conc[,1])
plot(conc[,100])
plot(conc[,1])
plot(conc[,100])
time = paste0(seq(1,ncol(conc)))
df <- data.frame(cbind(time, t(conc)))
library(tidyverse)
library(reshape2)
colnames(df) <- c('time', as.cahracter(paste0(seq(1, nrow(conc))))
colnames(df) <- c('time', as.character(paste0(seq(1, nrow(conc))))
colnames(df) <- c('time', as.character(paste0(seq(1, nrow(conc))))
colnames(df) <- c('time', as.character(paste0(seq(1, nrow(conc))))
time = 100
space = 100
conc <- matrix(0, nrow = space, ncol = time)
K = 0.5
dx = 1
dt = 1
conc[, 1] <- dnorm(seq(1,space,1), mean = 50, sd = 1) * 100
for (n in 2:ncol(conc)){
for (i in 2:(nrow(conc)-1)){
conc[i, n] = conc[i, n-1] +  K * dt/dx^2 * (conc[i-1, n-1] - 2 * conc[i, n-1] + conc[i+1, n-1])
}
}
# Let's plot this!
library(tidyverse)
library(reshape2)
time =  paste0(seq(1,ncol(conc)))
df <- data.frame(cbind(time, t(conc)) )
colnames(df) <- c("time", as.character(paste0(seq(1,nrow(conc)))))
m.df <- reshape2::melt(df, "time")
m.df$time <- time
ggplot(m.df, aes(as.numeric(time), as.numeric(variable))) +
geom_raster(aes(fill = as.numeric(value)), interpolate = TRUE) +
scale_fill_gradientn(limits = c(-1,100),
colours = rev(RColorBrewer::brewer.pal(11, 'Spectral')))+
theme_minimal()  +xlab('Time') +
ylab('Depth') +
labs(fill = 'Conc. [%]')
remotes::install_github('eco4cast/neon4cast')
library(tidyverse)
# dO2/dt = Flux * (O2 / (Khalf + O2)) * Theta^(Temp - 20) * Area
# g/day = g/m2/day  * m2
# Normal distributions for parameter assumptions
Flux <- rnorm(1, mean = -0.32, sd = -0.096)  # (g / m2 / d)
Khalf <- rnorm(1, mean = 0.224, sd = 0.032)   # (g / m3)
Theta <- rnorm(1, mean = 1.07, sd = 0.03) # (-)
dt = 1
library(rLakeAnalyzer)
library(LakeMetabolizer)
Temp_raw <- read_delim('InputTest/temperate/output_temp.txt', skip = 8, delim = '\t')
setwd("~/Projects/GLEON2022/EezyPeezyISIOxy")
library(tidyverse)
# dO2/dt = Flux * (O2 / (Khalf + O2)) * Theta^(Temp - 20) * Area
# g/day = g/m2/day  * m2
# Normal distributions for parameter assumptions
Flux <- rnorm(1, mean = -0.32, sd = -0.096)  # (g / m2 / d)
Khalf <- rnorm(1, mean = 0.224, sd = 0.032)   # (g / m3)
Theta <- rnorm(1, mean = 1.07, sd = 0.03) # (-)
dt = 1
library(rLakeAnalyzer)
library(LakeMetabolizer)
Temp_raw <- read_delim('InputTest/temperate/output_temp.txt', skip = 8, delim = '\t')
str(Temp_raw)
head(Temp_raw)
Depth_raw <- read_delim('InputTest/temperate/output_z.txt', skip = 8, delim = '\t')
Depth <- as.numeric(Depth_raw[1, -1]) * (-1)
Temp <- Temp_raw
colnames(Temp) <- c('Datetime', paste0('wtr_', Depth))
Temp <- data.frame('datetime' = Temp$Datetime, rev(Temp[, 2:ncol(Temp)]))
head(Temp)
Temp <- Temp %>%
dplyr::filter('datetime' >= as.POSIXct('2000-01-01') &
'datetime' <= as.POSIXct('2000-12-31'))
Temp$datetime
Temp <- Temp %>%
dplyr::filter('datetime' >= as.POSIXct('2000-01-01 UTC') &
'datetime' <= as.POSIXct('2000-12-31 UTC'))
str(Temp)
Temp <- Temp %>%
dplyr::filter('datetime' >= as.POSIXct('2000-01-01') &
'datetime' <= as.POSIXct('2000-12-31'))
Temp <- Temp %>%
dplyr::filter('datetime' >= as.POSIXct('2000-01-01'))
Temp %>%
dplyr::filter('datetime' >= as.POSIXct('2000-01-01') &
'datetime' <= as.POSIXct('2000-12-31'))
Temp <- Temp %>%
dplyr::filter('datetime' >= as.POSIXct('2000-01-01') &&
'datetime' <= as.POSIXct('2000-12-31'))
Temp <- Temp %>%
dplyr::filter('datetime' >= as.POSIXct('2000-01-01'),
'datetime' <= as.POSIXct('2000-12-31'))
Temp <- Temp %>%
dplyr::filter(datetime >= as.POSIXct('2000-01-01') &
datetime <= as.POSIXct('2000-12-31'))
Temp
Stratification <- data.frame('Datetime' = Temp$datetime, 'Density.Diff' = water.density(Temp[, ncol(Temp)]) - water.density(Temp[, 2]))
Stratification$Stratif.Check <- ifelse(Density.Diff >= 0.1, 1, NA)
ggplot(Stratification) + geom_line(aes(Datetime, Stratif.Check))
Stratification$Stratif.Check <- ifelse(Stratification$Density.Diff >= 0.1, 1, NA)
ggplot(Stratification) + geom_line(aes(Datetime, Stratif.Check))
Thermocline.depth <- ts.center.buoyancy(wtr = Temp)
str(Thermocline.depth)
ggplot(subset(Thermocline.depth, datetime > as.Date('2000-01-01') &
datetime < as.Date('2000-12-31')),
aes(datetime, cent.n2)) +
geom_path() +
geom_smooth() +
scale_y_reverse()
Area_raw <- read_delim('InputTest/temperate/hypsograph.dat', skip = 8, delim = '\t')
Area_raw
Area_raw <- read_delim('InputTest/temperate/hypsograph.dat', skip = 0, delim = '\t')
Area_raw
Area_raw <- read_delim('InputTest/temperate/hypsograph.dat', skip = 0, delim = '\t',col_names = F)
Area_raw
Area_raw <- read_delim('InputTest/temperate/hypsograph.dat', skip = 1, delim = '\t',
col_names = F)
Area_raw
max(depth)
max(Depth)
Area = Area_raw
Area = data.frame('Depth' = Area_raw[, 1] - max(Area_raw$X1), 'Area' = Area_raw[, 2])
Area = data.frame('Depth' = Area_raw[, 1] - max(Area_raw[, 1]), 'Area' = Area_raw[, 2])
Area_raw[,1]
as.numeric(Area_raw)
as.numeric(unlist(Area_raw))
